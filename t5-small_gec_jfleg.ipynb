{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351,
     "referenced_widgets": [
      "25a1a3d4688c494e86d91c0e6c3c1c85",
      "fa18af38b9414e53ac8e162ba53af53b",
      "dbdfcd01d53141f4a2ff9ff0f4904d10",
      "c3878623bba846789a80f1dece7c1ec5",
      "2a5a4961a30c42e78fdb8e6ff3c428c0",
      "5c9b0a0c28a24686a85f1ad02efc6910",
      "5a28b4af225d4a8eb0923d5e660fbe5f",
      "7bdef5b2970f4effb050b83d6f5ac484",
      "c09ccd758255426ab90b2e5b9f5bb387",
      "234293c838a64a31b911f6848590a634",
      "ab9e105ad6fb4a8996c5ab3f33fb5c56",
      "05cfd85eb4984f7fb6aaae0808e9e47f",
      "c0a9f30122a647efbc5bc8a4e851d5a5",
      "7ca17ecaecfa4d909890897c3ca7e9ed",
      "8cd9c63ad9a34172bac0808b9bcf856c",
      "4975ea1319fc41b485c46ad464fef80c",
      "0324b685eae34bffa940aaa73b5eb74c",
      "bd0e29085e104bc880506a636bb54f41",
      "7dd25e851a5645e2ad18cb92d33c2e16",
      "cd7c252e7c794f76b548659773246511",
      "64e50479158643e0aa7513d6d8df83cc",
      "0a62641449d24d95813b79535158113b",
      "51543c8167c442db8b5e2ab8316456a1",
      "070f6cef9c8d4c038e227d9f1d9c0902",
      "8dd8db0a29424e3f8af258048e28afc3",
      "3ffb637b7bd9440180788275fe6221cf",
      "88869059a60242d29bb19e47b8f337ae",
      "77f54886769f4c4780cf967d00495942",
      "5b4402bc00214a379bdfe67240eacac8",
      "5712b45763514c1a89b66ad7df7d362d",
      "761b3ef321454eb792392db2828b103c",
      "28925d5b0fb1432f9ce70ece8dce3426",
      "b26ed05010b44db58cf0a340d0a91937",
      "c0301ba0068447f39ba01d04e9df5d15",
      "28c5d67580b74aacb7e2719e0e69f0ed",
      "2332934c4a9a4f7bb9f361740b285633",
      "b688052aec2c4a6780f68d6c085b24d3",
      "83ff40d52b474b46a9a00429e113468d",
      "39679365d39a4651873418d1c40e3cbd",
      "7b3831e193794fb9860e1e9aed0b0c2d",
      "8650fea3258e40738d7711792f1ae432",
      "f6b3c5a055e14fac8faecaf33d95d83f",
      "129d0322b43b45ab9fb248480796a7e7",
      "2e87444d4f2d4f79a4e6577b5107cddc",
      "751cc8da36fd43daa526253aab3fe63e",
      "a3bfb9bb35354b8fa96f8c907e404479",
      "30296f5245964dfb8df5d58c3ab1f2b9",
      "18fb40a98c9a4acab01244fc23d32374",
      "9c35faa8b14349f5b8988ff8929e4a3e",
      "4a9eca9d7bd743f5a1ef1f51f4edec61",
      "d8d084e2434b42e7aa4ff98dd2808a06",
      "281a621a9cf24335b25902eb87a48395",
      "b31cbad0805544b293b5a3d36195fd7e",
      "bb915cf4fa034e3e9e4c1531be437de1",
      "2bcd5ba635cf448fa4edae3f8fe3364d",
      "af17cd2c268942e9b4974d927297ab74",
      "ef4a76deeb0c499491540b79abd3c07b",
      "415967d6d90040879f879f445746c81e",
      "fe48681e6753428ca24fb19ffafe2aa3",
      "7199a037221c4b1f9508d5ec76901b41",
      "496ef37c6c45494cb3f7798733c5adcf",
      "8651dddbc03a4c31bb84dfea2996b8f5",
      "5c90516aa79b4c899ce698e15a761b1e",
      "f33e2802545b4f5abd36f4d104a10ed8",
      "c5ff9b31b90c45859513ad560900b3ea",
      "5dafd5363ce04e37ac09e1c72e8227eb"
     ]
    },
    "id": "jugtauP_okF1",
    "outputId": "64a486de-b8af-469f-8ef4-621aaeb552ca"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uPyWYQv35hz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])  # Access 'input_ids'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJbuD3MD--Tk",
    "outputId": "686a339f-b903-4772-dbfd-2eff110da62d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qU datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "e651cce0768641fc925fa74c1db2ca1f",
      "23f3769a8ba94c70a0ff05b2c1e438b2",
      "71c9288beada471fade0ec1b5de44465",
      "59519dd0496648ac9f868ccb8ca5ec3c",
      "a4164b9bf9054aa3bc4b5c1f752b0410",
      "3b4694d516cf4147b70c3c854de90d7a",
      "7e29a6831a8b48768c119d355ef2003c",
      "6746a950a8f34065a247eecedd1e1cd4",
      "3d764eb102fd4c37a7524e8e12431cf2",
      "dd0337c4e7d64d9aa84ff9e53ae21bbb",
      "40aceda37a434bf6a278fdd38299a9ac",
      "f53e40b4533044279e754bc33598b064",
      "67de064dadec44fc86334006fcdbedb3",
      "70fd7a18a66c4640b0d498f80045c6db",
      "8794ea628bca4fd0830c64a82f6c5417",
      "895e8bd1a30c452b8c2e38574025d12f",
      "5c55c9be8db545549b51baa951190289",
      "452f74e67b384a779cceb1c715943e8e",
      "c96b5ffda12d4fe0a0736cfc2ebd4f10",
      "efe6d09161d348278e64f75b59b45200",
      "8cc7eb7858704b2ba6c82ed74d2f7fc5",
      "4083a3bb1d864df296f67dacbce783bf",
      "dec638d12a1443efb6e4d75ff3434d68",
      "a4477bfb676c4e29b590417ae2f9c4e4",
      "7eb2ba50f29040fbade63e9fb4ffa92c",
      "46bc97b7febb494d9cb76ed674634d53",
      "480a6d192a684d0485b2b3b54934408f",
      "b4175fa4744043ffb897e4fff25be708",
      "a0c1e9ed0b1840398363fc9687209eb5",
      "fadab00a1ca44c4da5c297a5962f6985",
      "d7c8f7b3f4e047af9837a39cc5a62ae2",
      "3b915c0318d4466f8f9b8016e5c853b0",
      "9c92dc240a6c4173be70fc4bdf5217c8",
      "e6f6abc8720144f6913cc6a6a2f40067",
      "5055058904dc4ebcad0488db1e597aa3",
      "fdbfa8085c2e4ef0aa076b3392fbf626",
      "48407a0f06564051ac8ee3c7c5a7b001",
      "a1e1afe5a1884794b77763012c4c47b5",
      "cbc941e30d954d2cac4c291de24aba7d",
      "ee86a6d34add41a7945ac37c6a3fb950",
      "dc79d59654604ef6b7c899a1cfd884f4",
      "707660414f2e4ef8b5c90fae5e89ead3",
      "7ba364e22daf45469e3fe1cba9ebb44c",
      "2c8fd3e05ae349cda7fa6a75ed3fd3c7",
      "ee3d8d09aca84db6b9adb4ddaaff090c",
      "a4888037dfd643a6b26606c2e4ae4524",
      "67665663bf954e798327a065ac15c5f5",
      "a22bfd222c804cf881167c9a381cfaf4",
      "c6da4a49c5d141fe8da8f753f7c63035",
      "5722b4b9ccc343d1b0f2837320bf51c7",
      "a18c1bfda42645d6add88a148fb8c2f7",
      "c8c990a2d24b4dd9ba2fdba520d7f3db",
      "2967d8eedcd94ffea016eacc143f9db7",
      "1cb5e1bb5dac42629a705c9c211dc41f",
      "d86f1ccf0c6c45d8a5323646efe4fb32"
     ]
    },
    "id": "iGqkMCSG-7_z",
    "outputId": "a8704f5c-7a8a-48fa-90df-ed9e1a4cf363"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e651cce0768641fc925fa74c1db2ca1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53e40b4533044279e754bc33598b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec638d12a1443efb6e4d75ff3434d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f6abc8720144f6913cc6a6a2f40067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/755 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d8d09aca84db6b9adb4ddaaff090c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'corrections'],\n",
      "    num_rows: 755\n",
      "})\n",
      "So I think we can not live if old people could not find siences and tecnologies and they did not developped . \n",
      "['So I think we would not be alive if our ancestors did not develop sciences and technologies . ', 'So I think we could not live if older people did not develop science and technologies . ', 'So I think we can not live if old people could not find science and technologies and they did not develop . ', 'So I think we can not live if old people can not find the science and technology that has not been developed . ']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import csv\n",
    "\n",
    "# JFLEG Dataset\n",
    "\n",
    "train_dataset = load_dataset(\"jfleg\", split='validation[:]')\n",
    "eval_dataset = load_dataset(\"jfleg\", split='test[:]')\n",
    "\n",
    "print(train_dataset)\n",
    "print(train_dataset['sentence'][0])\n",
    "print(train_dataset['corrections'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBoWblD__ScS"
   },
   "outputs": [],
   "source": [
    "replacements = [\n",
    "  (\" .\", \".\"),\n",
    "  (\" ,\", \",\"),\n",
    "  (\" '\", \"'\"),\n",
    "  (\" ?\", \"?\"),\n",
    "  (\" !\", \"!\"),\n",
    "  (\" :\", \"!\"),\n",
    "  (\" ;\", \"!\"),\n",
    "  (\" n't\", \"n't\"),\n",
    "  (\" v\", \"n't\"),\n",
    "  (\"2 0 0 6\", \"2006\"),\n",
    "  (\"5 5\", \"55\"),\n",
    "  (\"4 0 0\", \"400\"),\n",
    "  (\"1 7-5 0\", \"1750\"),\n",
    "  (\"2 0 %\", \"20%\"),\n",
    "  (\"5 0\", \"50\"),\n",
    "  (\"1 2\", \"12\"),\n",
    "  (\"1 0\", \"10\"),\n",
    "  ('\" ballast water', '\"ballast water')\n",
    "]\n",
    "\n",
    "def remove_excess_spaces(text):\n",
    "  for rep in replacements:\n",
    "    text = text.replace(rep[0], rep[1])\n",
    "\n",
    "  return text\n",
    "\n",
    "def generate_csv(csv_path, dataset):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writter = csv.writer(csvfile)\n",
    "        writter.writerow([\"input\", \"target\"])\n",
    "        for case in dataset:\n",
    "     \t    # Adding the task's prefix to input\n",
    "            input_text = \"grammar: \" + case[\"sentence\"]\n",
    "            input_text = remove_excess_spaces(input_text)\n",
    "            for correction in case[\"corrections\"]:\n",
    "              correction = remove_excess_spaces(correction)\n",
    "              # a few of the cases contain blank strings.\n",
    "              if input_text and correction:\n",
    "                writter.writerow([input_text, correction])\n",
    "\n",
    "# Generate train and eval for JFLEG Dataset\n",
    "!mkdir Dataset\n",
    "!mkdir Dataset/JFLEG\n",
    "generate_csv(\"Dataset/JFLEG/train.csv\", train_dataset)\n",
    "generate_csv(\"Dataset/JFLEG/eval.csv\", eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "c50ed812bebc4cc78fc9f9f049694790",
      "0ce27500c9674cb1843c2eb1ccd90b30",
      "ec42a9c54def4d86ac39ce0924572bc7",
      "ff4d9e0fb87d456dac89da1b53df6370",
      "5c6ed069189f48d2b874b1d4d437b3be",
      "ef04cfddc62c4b99ab0167682ec3710f",
      "d5a6ae5ba4d34ad3a4405be5dffc7e3b",
      "0f49603d6659410f86e45fd86c3160d7",
      "59d4c5f2f666438a8a11c67e8825f161",
      "dc41caef37d7441b9a88cbb3172af1ac",
      "1ebfe08afc7f4d8a94f9a2ba47f39b09",
      "29ffc82f9e994edd8b4af1da0f799ef5",
      "6609382874224e43a505403f9bc594f1",
      "9997b4c800a8484db74522e289d16857",
      "d5e8135562f249cdbcf8e6f3c03d8820",
      "0595426137a84c04a5d122e9a7789020",
      "568d8f93139b47eca9e31bb4ab2f2333",
      "5261eec38d6c4a86805a0b30dbb375fb",
      "24bb819fd2d64ae8a05c163a9d40fa24",
      "b4814e57591046af9a0dd3e97a65200f",
      "e4ce0731b1df4620b8ab78c6b851b91a",
      "91e762a1f59140b2acb995c3cfe99df1"
     ]
    },
    "id": "fB6ctwA6_gMb",
    "outputId": "571771b5-c636-4845-ee37-5d8f4c649118"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50ed812bebc4cc78fc9f9f049694790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/937 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ffc82f9e994edd8b4af1da0f799ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c4_200m.py:   0%|          | 0.00/2.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repository for liweili/c4_200m contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/liweili/c4_200m.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N] y\n"
     ]
    }
   ],
   "source": [
    "# C4_200M Dataset\n",
    "\n",
    "c4_dataset = load_dataset(\"liweili/c4_200m\", streaming = True)\n",
    "\n",
    "iterator = iter(c4_dataset['train'])\n",
    "\n",
    "def c4_generate_csv(csv_path, iterator, num_examples):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writter = csv.writer(csvfile)\n",
    "        writter.writerow([\"input\", \"target\"])\n",
    "        for i in range(0,num_examples):\n",
    "          data = next(iterator)\n",
    "          input_text = \"grammar: \" + data[\"input\"]\n",
    "          input_text = remove_excess_spaces(input_text)\n",
    "          correction = remove_excess_spaces(data[\"output\"])\n",
    "          if input_text and correction:\n",
    "            writter.writerow([input_text, correction])\n",
    "\n",
    "# Generate first 3500 examples from C4_200M dataset\n",
    "!mkdir Dataset/C4_200M\n",
    "c4_generate_csv(\"Dataset/C4_200M/c4data.csv\", iterator, num_examples=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4iC5gRdCP2a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jfleg_train = pd.read_csv(\"Dataset/JFLEG/train.csv\")\n",
    "jfleg_eval = pd.read_csv(\"Dataset/JFLEG/eval.csv\")\n",
    "c4_data = pd.read_csv(\"Dataset/C4_200M/c4data.csv\")\n",
    "\n",
    "combined_data = pd.concat([jfleg_train, jfleg_eval, c4_data], ignore_index=True)\n",
    "\n",
    "combined_data.to_csv(\"combined_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44xYYPCSNNlq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "combined_data = pd.read_csv(\"combined_data.csv\")\n",
    "\n",
    "train_data, eval_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "eval_data.to_csv(\"eval_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rnYVxFSRXVB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "eval_data = pd.read_csv(\"eval_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkOmyGjSRHjt"
   },
   "outputs": [],
   "source": [
    "train_texts = train_data[\"input\"].tolist()\n",
    "train_labels = train_data[\"target\"].tolist()\n",
    "\n",
    "eval_texts = eval_data[\"input\"].tolist()\n",
    "eval_labels = eval_data[\"target\"].tolist()\n",
    "\n",
    "train_inputs = tokenizer(train_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "train_labels = tokenizer(train_labels, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "eval_inputs = tokenizer(eval_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "eval_labels = tokenizer(eval_labels, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "train_dataset = TextDataset(train_inputs, train_labels)\n",
    "eval_dataset = TextDataset(eval_inputs, eval_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1YoiR8qVLmC"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "w8GwLc60QHyH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "440580dd-9e35-4257-af07-76f8be4ce833"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7140' max='7140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7140/7140 2:43:32, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.059900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.048800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n",
      "<ipython-input-2-e75158233947>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "<ipython-input-2-e75158233947>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Access 'input_ids'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7140, training_loss=0.07537648464117397, metrics={'train_runtime': 9815.3809, 'train_samples_per_second': 23.238, 'train_steps_per_second': 0.727, 'total_flos': 3.087011149774848e+16, 'train_loss': 0.07537648464117397, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfBVa9nEgEf1",
    "outputId": "b8c47ab6-972d-44f1-fe78-c03b09a16292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can your help me please.\n"
     ]
    }
   ],
   "source": [
    "test_text = \"can your help me please.\"  \n",
    "test_inputs = tokenizer(test_text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**test_inputs)\n",
    "\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R49a-W-2gkXl",
    "outputId": "4f5db30a-5fa9-446d-ca7b-831d656ded7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('grammar_correction_model/tokenizer_config.json',\n",
       " 'grammar_correction_model/special_tokens_map.json',\n",
       " 'grammar_correction_model/spiece.model',\n",
       " 'grammar_correction_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"grammar_correction_model\")\n",
    "tokenizer.save_pretrained(\"grammar_correction_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rRlRnbETpZS",
    "outputId": "cb4cbcfd-4ab1-42f7-efb1-bcb33ed8ca89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: grammar_correction_model/added_tokens.json (deflated 83%)\n",
      "  adding: grammar_correction_model/config.json (deflated 62%)\n",
      "  adding: grammar_correction_model/generation_config.json (deflated 29%)\n",
      "  adding: grammar_correction_model/model.safetensors (deflated 9%)\n",
      "  adding: grammar_correction_model/special_tokens_map.json (deflated 85%)\n",
      "  adding: grammar_correction_model/spiece.model (deflated 48%)\n",
      "  adding: grammar_correction_model/tokenizer_config.json (deflated 94%)\n"
     ]
    }
   ],
   "source": [
    "!zip grammar_correction_model.zip grammar_correction_model/*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
