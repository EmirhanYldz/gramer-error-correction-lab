{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-19T20:16:39.258548Z",
     "iopub.status.busy": "2025-05-19T20:16:39.258289Z",
     "iopub.status.idle": "2025-05-19T20:16:39.278819Z",
     "shell.execute_reply": "2025-05-19T20:16:39.277742Z",
     "shell.execute_reply.started": "2025-05-19T20:16:39.258522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/config.json\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/spiece.model\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/training_args.bin\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/tokenizer_config.json\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/model.safetensors\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/special_tokens_map.json\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/added_tokens.json\n",
      "/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1/generation_config.json\n",
      "/kaggle/input/c4-000-010/C4_200M.tsv-00000-of-00010\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:16:45.387333Z",
     "iopub.status.busy": "2025-05-19T20:16:45.386971Z",
     "iopub.status.idle": "2025-05-19T20:16:49.056156Z",
     "shell.execute_reply": "2025-05-19T20:16:49.054881Z",
     "shell.execute_reply.started": "2025-05-19T20:16:45.387303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "with open(\"/kaggle/input/c4-000-010/C4_200M.tsv-00000-of-00010\", \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    pieces = line.strip().split('\\t')\n",
    "    src = pieces[0]\n",
    "    tgt = pieces[1]\n",
    "\n",
    "    data.append([src, tgt])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"src\", \"tgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:16:49.057757Z",
     "iopub.status.busy": "2025-05-19T20:16:49.057418Z",
     "iopub.status.idle": "2025-05-19T20:16:50.473638Z",
     "shell.execute_reply": "2025-05-19T20:16:50.473074Z",
     "shell.execute_reply.started": "2025-05-19T20:16:49.057715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_csv(\"/kaggle/working/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:16:50.478778Z",
     "iopub.status.busy": "2025-05-19T20:16:50.478065Z",
     "iopub.status.idle": "2025-05-19T20:16:55.758725Z",
     "shell.execute_reply": "2025-05-19T20:16:55.757911Z",
     "shell.execute_reply.started": "2025-05-19T20:16:50.478758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle().take(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:16:55.759884Z",
     "iopub.status.busy": "2025-05-19T20:16:55.759628Z",
     "iopub.status.idle": "2025-05-19T20:17:04.191656Z",
     "shell.execute_reply": "2025-05-19T20:17:04.191019Z",
     "shell.execute_reply.started": "2025-05-19T20:16:55.759866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 20:17:00.715667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747685820.740263    5921 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747685820.747865    5921 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:04.193005Z",
     "iopub.status.busy": "2025-05-19T20:17:04.192524Z",
     "iopub.status.idle": "2025-05-19T20:17:04.198241Z",
     "shell.execute_reply": "2025-05-19T20:17:04.196982Z",
     "shell.execute_reply.started": "2025-05-19T20:17:04.192986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    input = [\"gec: \" + src for src in example[\"src\"]]\n",
    "    target = example[\"tgt\"]\n",
    "    result = tokenizer(input, text_target=target, truncation=True, padding=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:04.199183Z",
     "iopub.status.busy": "2025-05-19T20:17:04.198945Z",
     "iopub.status.idle": "2025-05-19T20:17:49.613137Z",
     "shell.execute_reply": "2025-05-19T20:17:49.612470Z",
     "shell.execute_reply.started": "2025-05-19T20:17:04.199159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be395b54312d476bbc2099f941442fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset= dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:49.613999Z",
     "iopub.status.busy": "2025-05-19T20:17:49.613805Z",
     "iopub.status.idle": "2025-05-19T20:17:49.619927Z",
     "shell.execute_reply": "2025-05-19T20:17:49.619288Z",
     "shell.execute_reply.started": "2025-05-19T20:17:49.613985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(['src','tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:49.620950Z",
     "iopub.status.busy": "2025-05-19T20:17:49.620735Z",
     "iopub.status.idle": "2025-05-19T20:17:50.033926Z",
     "shell.execute_reply": "2025-05-19T20:17:50.033302Z",
     "shell.execute_reply.started": "2025-05-19T20:17:49.620934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_test_dataset = tokenized_dataset.train_test_split(test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:50.034855Z",
     "iopub.status.busy": "2025-05-19T20:17:50.034661Z",
     "iopub.status.idle": "2025-05-19T20:17:50.040164Z",
     "shell.execute_reply": "2025-05-19T20:17:50.039480Z",
     "shell.execute_reply.started": "2025-05-19T20:17:50.034840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 98000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:50.041430Z",
     "iopub.status.busy": "2025-05-19T20:17:50.040920Z",
     "iopub.status.idle": "2025-05-19T20:17:50.725171Z",
     "shell.execute_reply": "2025-05-19T20:17:50.724567Z",
     "shell.execute_reply.started": "2025-05-19T20:17:50.041410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"/kaggle/input/gec-flan-t5-base/transformers/default/1/kaggle/working/gec_model1\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:50.727457Z",
     "iopub.status.busy": "2025-05-19T20:17:50.727005Z",
     "iopub.status.idle": "2025-05-19T20:17:50.775279Z",
     "shell.execute_reply": "2025-05-19T20:17:50.774472Z",
     "shell.execute_reply.started": "2025-05-19T20:17:50.727438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5921/2017458482.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps = 1000,\n",
    "    learning_rate=2e-5,\n",
    "    bf16=True,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps = 1000,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test_dataset['train'],\n",
    "    eval_dataset=train_test_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:17:50.776373Z",
     "iopub.status.busy": "2025-05-19T20:17:50.776099Z",
     "iopub.status.idle": "2025-05-20T00:45:05.002225Z",
     "shell.execute_reply": "2025-05-20T00:45:05.001546Z",
     "shell.execute_reply.started": "2025-05-19T20:17:50.776349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T00:45:05.005694Z",
     "iopub.status.busy": "2025-05-20T00:45:05.005230Z",
     "iopub.status.idle": "2025-05-20T00:45:06.907398Z",
     "shell.execute_reply": "2025-05-20T00:45:06.906764Z",
     "shell.execute_reply.started": "2025-05-20T00:45:05.005668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"gec_model_c4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T00:45:06.908241Z",
     "iopub.status.busy": "2025-05-20T00:45:06.908058Z",
     "iopub.status.idle": "2025-05-20T00:45:59.454649Z",
     "shell.execute_reply": "2025-05-20T00:45:59.453711Z",
     "shell.execute_reply.started": "2025-05-20T00:45:06.908227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/gec_model_c4/ (stored 0%)\n",
      "  adding: kaggle/working/gec_model_c4/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/gec_model_c4/tokenizer_config.json (deflated 94%)\n",
      "  adding: kaggle/working/gec_model_c4/config.json (deflated 62%)\n",
      "  adding: kaggle/working/gec_model_c4/added_tokens.json (deflated 83%)\n",
      "  adding: kaggle/working/gec_model_c4/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/gec_model_c4/special_tokens_map.json (deflated 85%)\n",
      "  adding: kaggle/working/gec_model_c4/generation_config.json (deflated 29%)\n",
      "  adding: kaggle/working/gec_model_c4/spiece.model (deflated 48%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r gec_model_c4.zip /kaggle/working/gec_model_c4"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7461453,
     "sourceId": 11872872,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 350341,
     "modelInstanceId": 329511,
     "sourceId": 402918,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
